{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfx-tfdf-e2e-run",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4xZLCIeLUB1taTg1AOgsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertf99/tfx-e2e/blob/main/tfx_tfdf_e2e_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y-vsj2fdVWJG",
        "outputId": "b3ae32f1-ce60-402c-f65c-685bf3e8a483"
      },
      "source": [
        "!pip install -U tensorflow_decision_forests tfx==1.0.0 wurlitzer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: requests, prompt-toolkit, packaging, ipython, grpcio-gcp, google-crc32c, pyarrow, proto-plus, hdfs, grpc-google-iam-v1, google-resumable-media, google-cloud-core, future, fasteners, fastavro, dill, avro-python3, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-pubsub, google-cloud-profiler, google-cloud-language, google-cloud-dlp, google-cloud-bigtable, google-cloud-bigquery, google-apitools, apache-beam, websocket-client, tensorflow-serving-api, tensorflow-metadata, joblib, attrs, tfx-bsl, terminaltables, ml-metadata, google-cloud-storage, docker, colorama, tensorflow-transform, tensorflow-model-analysis, tensorflow-data-validation, ml-pipelines-sdk, kubernetes, keras-tuner, google-cloud-aiplatform, wurlitzer, tfx, tensorflow-decision-forests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Uninstalling packaging-21.0:\n",
            "      Successfully uninstalled packaging-21.0\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: google-cloud-language\n",
            "    Found existing installation: google-cloud-language 1.2.0\n",
            "    Uninstalling google-cloud-language-1.2.0:\n",
            "      Successfully uninstalled google-cloud-language-1.2.0\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 1.21.0\n",
            "    Uninstalling google-cloud-bigquery-1.21.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.1.0\n",
            "    Uninstalling tensorflow-metadata-1.1.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.1.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.18.0 which is incompatible.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.19 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.31.0 attrs-20.3.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 docker-4.4.4 fastavro-1.4.4 fasteners-0.16.3 future-0.18.2 google-apitools-0.5.31 google-cloud-aiplatform-0.7.1 google-cloud-bigquery-2.18.0 google-cloud-bigtable-1.7.0 google-cloud-core-1.7.2 google-cloud-dlp-1.0.0 google-cloud-language-1.3.0 google-cloud-profiler-3.0.5 google-cloud-pubsub-1.7.0 google-cloud-spanner-1.19.1 google-cloud-storage-1.41.1 google-cloud-videointelligence-1.16.1 google-cloud-vision-1.0.0 google-crc32c-1.1.2 google-resumable-media-1.3.3 grpc-google-iam-v1-0.12.3 grpcio-gcp-0.2.2 hdfs-2.6.0 ipython-7.26.0 joblib-0.14.1 keras-tuner-1.0.1 kubernetes-11.0.0 ml-metadata-1.0.0 ml-pipelines-sdk-1.0.0 packaging-20.9 prompt-toolkit-3.0.19 proto-plus-1.19.0 pyarrow-2.0.0 requests-2.26.0 tensorflow-data-validation-1.0.0 tensorflow-decision-forests-0.1.8 tensorflow-metadata-1.0.0 tensorflow-model-analysis-0.31.0 tensorflow-serving-api-2.5.1 tensorflow-transform-1.0.0 terminaltables-3.1.0 tfx-1.0.0 tfx-bsl-1.0.0 websocket-client-1.1.0 wurlitzer-2.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "google",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcoydHZFVpP6",
        "outputId": "20ae6ead-f1f0-454b-ad98-2964d029df4b"
      },
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import math\n",
        "\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.5.0\n",
            "TFX version: 1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxftndHIVx1H"
      },
      "source": [
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIpbBLxTWlX-"
      },
      "source": [
        "## 0. Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM21gRs2WoR4"
      },
      "source": [
        "import os\n",
        "\n",
        "# We will create two pipelines. One for schema generation and one for training.\n",
        "SCHEMA_PIPELINE_NAME = \"penguin-tfdv-schema\"\n",
        "PIPELINE_NAME = \"penguin-tfdv\"\n",
        "\n",
        "# Output directory to store artifacts generated from the pipeline.\n",
        "SCHEMA_PIPELINE_ROOT = os.path.join('pipelines', SCHEMA_PIPELINE_NAME)\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "# Path to a SQLite DB file to use as an MLMD storage.\n",
        "SCHEMA_METADATA_PATH = os.path.join('metadata', SCHEMA_PIPELINE_NAME,\n",
        "                                    'metadata.db')\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
        "\n",
        "# Output directory where created models from the pipeline will be exported.\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "\n",
        "SAVED_SCHEMA_NAME = \"schema.pbtxt\"\n",
        "SAVED_SCHEMA_PATH = os.path.join(\"schema\", SCHEMA_PIPELINE_NAME, SAVED_SCHEMA_NAME)\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)  # Set default logging level."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS1U6LMazLMh"
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-raOqLZBWbrE"
      },
      "source": [
        "## 1. Data Ready\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxP8IJaTWFYA",
        "outputId": "e4348855-ced5-462b-d267-5e3c1cccfff0"
      },
      "source": [
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
        "_data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv'\n",
        "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
        "urllib.request.urlretrieve(_data_url, _data_filepath)\n",
        "!head {_data_filepath}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "species,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex,year\n",
            "Adelie,Torgersen,39.1,18.7,181,3750,male,2007\n",
            "Adelie,Torgersen,39.5,17.4,186,3800,female,2007\n",
            "Adelie,Torgersen,40.3,18,195,3250,female,2007\n",
            "Adelie,Torgersen,NA,NA,NA,NA,NA,2007\n",
            "Adelie,Torgersen,36.7,19.3,193,3450,female,2007\n",
            "Adelie,Torgersen,39.3,20.6,190,3650,male,2007\n",
            "Adelie,Torgersen,38.9,17.8,181,3625,female,2007\n",
            "Adelie,Torgersen,39.2,19.6,195,4675,male,2007\n",
            "Adelie,Torgersen,34.1,18.1,193,3475,NA,2007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oy6U8aM0720"
      },
      "source": [
        "### 1.1 Label predictor column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DsGT46Rxpw-",
        "outputId": "cefb0146-9cba-4508-b81c-e4ad07cdf58b"
      },
      "source": [
        "dataset_df = pd.read_csv(_data_filepath)\n",
        "print(dataset_df.shape)\n",
        "# Name of the label column.\n",
        "label = \"species\"\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)\n",
        "clean_df = dataset_df.dropna()\n",
        "print(clean_df.shape)\n",
        "clean_df.to_csv(_data_filepath, index=False)\n",
        "!head {_data_filepath}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(344, 8)\n",
            "Label classes: ['Adelie', 'Gentoo', 'Chinstrap']\n",
            "(333, 8)\n",
            "species,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex,year\n",
            "0,Torgersen,39.1,18.7,181.0,3750.0,male,2007\n",
            "0,Torgersen,39.5,17.4,186.0,3800.0,female,2007\n",
            "0,Torgersen,40.3,18.0,195.0,3250.0,female,2007\n",
            "0,Torgersen,36.7,19.3,193.0,3450.0,female,2007\n",
            "0,Torgersen,39.3,20.6,190.0,3650.0,male,2007\n",
            "0,Torgersen,38.9,17.8,181.0,3625.0,female,2007\n",
            "0,Torgersen,39.2,19.6,195.0,4675.0,male,2007\n",
            "0,Torgersen,41.1,17.6,182.0,3200.0,female,2007\n",
            "0,Torgersen,38.6,21.2,191.0,3800.0,male,2007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BygrTZl6xQhY"
      },
      "source": [
        "## 2. Define Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYQd-lEtxoAT"
      },
      "source": [
        "### schema pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne3aZp3lxU-P"
      },
      "source": [
        "from tfx import v1 as tfx\n",
        "\n",
        "def create_schema_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "  \n",
        "  # Computes statistics over data for visualization and schema generation.\n",
        "  statistics_gen = tfx.components.StatisticsGen(\n",
        "      examples=example_gen.outputs['examples'])\n",
        "\n",
        "  # Generates schema based on the generated statistics.\n",
        "  schema_gen = tfx.components.SchemaGen(\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "\n",
        "  components = [\n",
        "      example_gen,\n",
        "      statistics_gen,\n",
        "      schema_gen\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PTBu88AXxu_q",
        "outputId": "ebf8926e-f1f9-4af9-c690-a6b54c65925f"
      },
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  create_schema_pipeline(\n",
        "      pipeline_name=SCHEMA_PIPELINE_NAME,\n",
        "      pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      metadata_path=SCHEMA_METADATA_PATH))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Running pipeline:\n",
            " pipeline_info {\n",
            "  id: \"penguin-tfdv-schema\"\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "      }\n",
            "      id: \"CsvExampleGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T11:31:15.238388\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Examples\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "              properties {\n",
            "                key: \"version\"\n",
            "                value: INT\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"input_base\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"input_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_data_format\"\n",
            "        value {\n",
            "          field_value {\n",
            "            int_value: 6\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    downstream_nodes: \"StatisticsGen\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "      }\n",
            "      id: \"StatisticsGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T11:31:15.238388\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"CsvExampleGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T11:31:15.238388\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Examples\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"examples\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"statistics\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ExampleStatistics\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"exclude_splits\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"[]\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"CsvExampleGen\"\n",
            "    downstream_nodes: \"SchemaGen\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "      }\n",
            "      id: \"SchemaGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T11:31:15.238388\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"statistics\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"StatisticsGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T11:31:15.238388\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"ExampleStatistics\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"statistics\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"schema\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"exclude_splits\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"[]\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"infer_feature_shape\"\n",
            "        value {\n",
            "          field_value {\n",
            "            int_value: 1\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"StatisticsGen\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "runtime_spec {\n",
            "  pipeline_root {\n",
            "    field_value {\n",
            "      string_value: \"pipelines/penguin-tfdv-schema\"\n",
            "    }\n",
            "  }\n",
            "  pipeline_run_id {\n",
            "    field_value {\n",
            "      string_value: \"2021-08-03T11:31:15.238388\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "execution_mode: SYNC\n",
            "deployment_config {\n",
            "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
            "  value: \"\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\n\\220\\001\\n\\rStatisticsGen\\022\\177\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\0223\\n1\\n/tfx.components.statistics_gen.executor.Executor\\n\\216\\001\\n\\tSchemaGen\\022\\200\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022-\\n+tfx.components.schema_gen.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver*b\\n0type.googleapis.com/ml_metadata.ConnectionConfig\\022.\\032,\\n(metadata/penguin-tfdv-schema/metadata.db\\020\\003\"\n",
            "}\n",
            "\n",
            "INFO:absl:Using deployment config:\n",
            " executor_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"SchemaGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"StatisticsGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "custom_driver_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "metadata_connection_config {\n",
            "  sqlite {\n",
            "    filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
            "    connection_mode: READWRITE_OPENCREATE\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using connection config:\n",
            " sqlite {\n",
            "  filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
            "  connection_mode: READWRITE_OPENCREATE\n",
            "}\n",
            "\n",
            "INFO:absl:Component CsvExampleGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 1\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/1\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}), exec_properties={'input_base': '/tmp/tfx-datar21onp4k', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185'}, execution_output_uri='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/stateful_working_dir/2021-08-03T11:31:15.238388', tmp_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T11:31:15.238388')\n",
            "INFO:absl:Generating examples.\n",
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Processing input csv data /tmp/tfx-datar21onp4k/* to TFExample.\n",
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
            "INFO:absl:Examples generated.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 1 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/1\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}) for execution 1\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component CsvExampleGen is finished.\n",
            "INFO:absl:Component StatisticsGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T11:31:15.238388\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"SchemaGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 2\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\n",
            "type_id: 6\n",
            "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/1\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627990277100\n",
            "last_update_time_since_epoch: 1627990277100\n",
            ", artifact_type: id: 6\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:StatisticsGen:statistics:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/stateful_working_dir/2021-08-03T11:31:15.238388', tmp_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T11:31:15.238388\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"SchemaGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T11:31:15.238388')\n",
            "INFO:absl:Generating statistics for split train.\n",
            "INFO:absl:Statistics for split train written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/2/Split-train.\n",
            "INFO:absl:Generating statistics for split eval.\n",
            "INFO:absl:Statistics for split eval written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/2/Split-eval.\n",
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 2 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:StatisticsGen:statistics:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}) for execution 2\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component StatisticsGen is finished.\n",
            "INFO:absl:Component SchemaGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "  }\n",
            "  id: \"SchemaGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T11:31:15.238388\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"infer_feature_shape\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 3\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 8\n",
            "uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:StatisticsGen:statistics:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627990280462\n",
            "last_update_time_since_epoch: 1627990280462\n",
            ", artifact_type: id: 8\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/SchemaGen/schema/3\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:SchemaGen:schema:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}), exec_properties={'exclude_splits': '[]', 'infer_feature_shape': 1}, execution_output_uri='pipelines/penguin-tfdv-schema/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/SchemaGen/.system/stateful_working_dir/2021-08-03T11:31:15.238388', tmp_dir='pipelines/penguin-tfdv-schema/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "  }\n",
            "  id: \"SchemaGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T11:31:15.238388\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T11:31:15.238388\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"infer_feature_shape\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T11:31:15.238388')\n",
            "INFO:absl:Processing schema from statistics for split train.\n",
            "INFO:absl:Processing schema from statistics for split eval.\n",
            "INFO:absl:Schema written to pipelines/penguin-tfdv-schema/SchemaGen/schema/3/schema.pbtxt.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 3 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/SchemaGen/schema/3\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:31:15.238388:SchemaGen:schema:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}) for execution 3\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component SchemaGen is finished.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "O24cB9FiyEP-",
        "outputId": "668849d1-5f56-4738-8a28-fccd3f648c51"
      },
      "source": [
        "from tfx.orchestration.metadata import Metadata\n",
        "from ml_metadata.proto import metadata_store_pb2\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.portable.mlmd import execution_lib\n",
        "from tfx.types import standard_component_specs\n",
        "import shutil\n",
        "\n",
        "\n",
        "# TODO(b/171447278): Move these functions into the TFX library.\n",
        "\n",
        "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
        "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
        "  context = metadata.store.get_context_by_type_and_name(\n",
        "      'node', f'{pipeline_name}.{component_id}')\n",
        "  executions = metadata.store.get_executions_by_context(context.id)\n",
        "  latest_execution = max(executions,\n",
        "                         key=lambda e:e.last_update_time_since_epoch)\n",
        "  return execution_lib.get_artifacts_dict(metadata, latest_execution.id, \n",
        "                                          metadata_store_pb2.Event.OUTPUT)\n",
        "\n",
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    SCHEMA_METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Find output artifacts from MLMD.\n",
        "  stat_gen_output = get_latest_artifacts(metadata_handler,SCHEMA_PIPELINE_NAME,\n",
        "                                         'StatisticsGen')\n",
        "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
        "\n",
        "  schema_gen_output = get_latest_artifacts(metadata_handler,\n",
        "                                           SCHEMA_PIPELINE_NAME, 'SchemaGen')\n",
        "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]\n",
        "\n",
        "\n",
        "os.makedirs(SAVED_SCHEMA_PATH, exist_ok=True)\n",
        "_generated_path = os.path.join(schema_artifacts[0].uri, SAVED_SCHEMA_NAME)\n",
        "\n",
        "# Copy the 'schema.pbtxt' file from the artifact uri to a predefined path.\n",
        "shutil.copy(_generated_path, SAVED_SCHEMA_PATH)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:MetadataStore with DB connection initialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'schema/penguin-tfdv-schema/schema.pbtxt/schema.pbtxt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u5AG0HuxkFR"
      },
      "source": [
        "### e2e piepline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmEVc_8jzgUa"
      },
      "source": [
        "TRAINER_MODULE_PATH = 'penguin_trainer.py'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeG7gw8ezRMX",
        "outputId": "6105a9f5-fb3a-4cf7-ad35-13d1cf817dd9"
      },
      "source": [
        "%%writefile {TRAINER_MODULE_PATH}\n",
        "\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "\n",
        "# from tfx_bsl.public import tfxio\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "from wurlitzer import sys_pipes\n",
        "\n",
        "_LABEL_KEY = \"species\"\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 238\n",
        "_EVAL_BATCH_SIZE = 95\n",
        "\n",
        "\n",
        "def _input_fn(\n",
        "    file_pattern: List[str],\n",
        "    data_accessor: tfx.components.DataAccessor,\n",
        "    schema: schema_pb2.Schema,\n",
        "    batch_size: int = 200,\n",
        ") -> tf.data.Dataset:\n",
        "    \"\"\"Generates features and label for training.\n",
        "\n",
        "    Args:\n",
        "      file_pattern: List of paths or patterns of input tfrecord files.\n",
        "      data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "      schema: schema of the input data.\n",
        "      batch_size: representing the number of consecutive elements of returned\n",
        "        dataset to combine in a single batch\n",
        "\n",
        "    Returns:\n",
        "      A dataset that contains (features, indices) tuple where features is a\n",
        "        dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "    \"\"\"\n",
        "\n",
        "    dataset = data_accessor.tf_dataset_factory(\n",
        "        file_pattern,\n",
        "        dataset_options.TensorFlowDatasetOptions(\n",
        "            batch_size=batch_size, label_key=_LABEL_KEY, num_epochs=1\n",
        "        ),\n",
        "        schema,\n",
        "    )\n",
        "\n",
        "    # def prepare_label(feature_dict):\n",
        "    #     # label_dict = tf.sparse.to_dense(\n",
        "    #     #     feature_dict.pop(_LABEL_KEY),\n",
        "    #     #     default_value=None,\n",
        "    #     #     validate_indices=True,\n",
        "    #     #     name=None,\n",
        "    #     # )\n",
        "    #     label_dict = feature_dict.pop(_LABEL_KEY)\n",
        "\n",
        "    #     return feature_dict, label_dict\n",
        "\n",
        "    # dataset = dataset.map(prepare_label)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def _build_tfdf_model():\n",
        "    model = tfdf.keras.RandomForestModel()\n",
        "    model.compile(metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "    \"\"\"Train the model based on given args.\n",
        "\n",
        "    Args:\n",
        "      fn_args: Holds args used to train the model as name/value pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    schema = tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema_pb2.Schema())\n",
        "    train_dataset = _input_fn(\n",
        "        fn_args.train_files, fn_args.data_accessor, schema, batch_size=_TRAIN_BATCH_SIZE\n",
        "    )\n",
        "    #   for features, label in train_dataset.take(1):  # only take first element of dataset\n",
        "    #     print('*************')\n",
        "    #     print(features)\n",
        "    #     print(label)\n",
        "    eval_dataset = _input_fn(\n",
        "        fn_args.eval_files, fn_args.data_accessor, schema, batch_size=_EVAL_BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    model = _build_tfdf_model()\n",
        "    with sys_pipes():\n",
        "        model.fit(\n",
        "            train_dataset,\n",
        "            # steps_per_epoch=fn_args.train_steps,\n",
        "            validation_data=eval_dataset,\n",
        "        )\n",
        "        # validation_steps=fn_args.eval_steps)\n",
        "        print(model.summary())\n",
        "\n",
        "    model.make_inspector().export_to_tensorboard(fn_args.model_run_dir)\n",
        "    # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "    # directory.\n",
        "    model.save(fn_args.serving_model_dir, save_format=\"tf\")\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting penguin_trainer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWP1eSGLxjlV"
      },
      "source": [
        "from tfx import v1 as tfx\n",
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "\n",
        "def create_schema_pipeline(\n",
        "    pipeline_name: str,\n",
        "    pipeline_root: str,\n",
        "    data_root: str,\n",
        "    metadata_path: str,\n",
        "    schema_path: str,\n",
        "    trainer_module_file: str,\n",
        "    serving_model_dir: str,\n",
        ") -> tfx.dsl.Pipeline:\n",
        "    \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "    # Split data\n",
        "    example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "    # Generate current data statistics\n",
        "    statistics_gen = tfx.components.StatisticsGen(\n",
        "        examples=example_gen.outputs[\"examples\"]\n",
        "    )\n",
        "\n",
        "    # Import saved schema\n",
        "    schema_importer = tfx.dsl.Importer(\n",
        "        source_uri=schema_path, artifact_type=tfx.types.standard_artifacts.Schema\n",
        "    ).with_id(\"schema_importer\")\n",
        "\n",
        "    # Validate Schema\n",
        "    example_validator = tfx.components.ExampleValidator(\n",
        "        statistics=statistics_gen.outputs[\"statistics\"],\n",
        "        schema=schema_importer.outputs[\"result\"],\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = tfx.components.Trainer(\n",
        "        module_file=trainer_module_file,\n",
        "        examples=example_gen.outputs[\"examples\"],\n",
        "        schema=schema_importer.outputs[\"result\"],  # Pass the imported schema.\n",
        "        train_args=tfx.proto.TrainArgs(),\n",
        "        eval_args=tfx.proto.EvalArgs(),\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    eval_config = tfma.EvalConfig(\n",
        "        model_specs=[\n",
        "            # This assumes a serving model with signature 'serving_default'. If\n",
        "            # using estimator based EvalSavedModel, add signature_name: 'eval' and\n",
        "            # remove the label_key.\n",
        "            tfma.ModelSpec(label_key=\"species\")\n",
        "        ],\n",
        "        metrics_specs=[\n",
        "            tfma.MetricsSpec(\n",
        "                metrics=[\n",
        "                    tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
        "                    tfma.MetricConfig(\n",
        "                        class_name=\"SparseCategoricalAccuracy\",\n",
        "                        threshold=tfma.MetricThreshold(\n",
        "                            value_threshold=tfma.GenericValueThreshold(\n",
        "                                lower_bound={\"value\": 0.9}\n",
        "                            ),\n",
        "                            # Change threshold will be ignored if there is no\n",
        "                            # baseline model resolved from MLMD (first run).\n",
        "                            change_threshold=tfma.GenericChangeThreshold(\n",
        "                                direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                                absolute={\"value\": -1e-10},\n",
        "                            ),\n",
        "                        ),\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "        ],\n",
        "        slicing_specs=[\n",
        "            # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "            tfma.SlicingSpec(),\n",
        "            # Data can be sliced along a feature column. In this case, data is\n",
        "            # sliced along feature column trip_start_hour.\n",
        "            tfma.SlicingSpec(feature_keys=[\"sex\"]),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model_resolver = tfx.dsl.Resolver(\n",
        "        strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "        model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "        model_blessing=tfx.dsl.Channel(type=tfx.types.standard_artifacts.ModelBlessing),\n",
        "    ).with_id(\"latest_blessed_model_resolver\")\n",
        "\n",
        "    evaluator = tfx.components.Evaluator(\n",
        "        examples=example_gen.outputs[\"examples\"],\n",
        "        model=trainer.outputs[\"model\"],\n",
        "        baseline_model=model_resolver.outputs[\"model\"],\n",
        "        eval_config=eval_config,\n",
        "    )\n",
        "\n",
        "    # Pusher\n",
        "    pusher = tfx.components.Pusher(\n",
        "        model=trainer.outputs[\"model\"],\n",
        "        model_blessing=evaluator.outputs[\"blessing\"],\n",
        "        push_destination=tfx.proto.PushDestination(\n",
        "            filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "                base_directory=serving_model_dir\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    components = [\n",
        "        example_gen,\n",
        "        statistics_gen,\n",
        "        schema_importer,\n",
        "        example_validator,\n",
        "        trainer,\n",
        "        evaluator,\n",
        "        pusher,\n",
        "    ]\n",
        "\n",
        "    return tfx.dsl.Pipeline(\n",
        "        pipeline_name=pipeline_name,\n",
        "        pipeline_root=pipeline_root,\n",
        "        metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "            metadata_path\n",
        "        ),\n",
        "        components=components,\n",
        "    )\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rgl0KPk6zCaY",
        "outputId": "b4eea3a6-2e11-4bb8-b027-5361c046dd53"
      },
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "    create_schema_pipeline(\n",
        "        pipeline_name=SCHEMA_PIPELINE_NAME,\n",
        "        pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
        "        data_root=DATA_ROOT,\n",
        "        metadata_path=SCHEMA_METADATA_PATH,\n",
        "        schema_path=SAVED_SCHEMA_PATH,\n",
        "        trainer_module_file=TRAINER_MODULE_PATH,\n",
        "        serving_model_dir=SERVING_MODEL_DIR,\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Generating ephemeral wheel package for '/content/penguin_trainer.py' (including modules: ['penguin_trainer']).\n",
            "INFO:absl:User module package has hash fingerprint version 3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '/tmp/tmp5ud5vvlk/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpypmkxsb4', '--dist-dir', '/tmp/tmpuimw8i0n']\n",
            "INFO:absl:Successfully built user code wheel distribution at 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl'; target user module is 'penguin_trainer'.\n",
            "INFO:absl:Full user module path is 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl'\n",
            "INFO:absl:Running pipeline:\n",
            " pipeline_info {\n",
            "  id: \"penguin-tfdv-schema\"\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "      }\n",
            "      id: \"CsvExampleGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Examples\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "              properties {\n",
            "                key: \"version\"\n",
            "                value: INT\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"input_base\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"input_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_data_format\"\n",
            "        value {\n",
            "          field_value {\n",
            "            int_value: 6\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    downstream_nodes: \"Evaluator\"\n",
            "    downstream_nodes: \"StatisticsGen\"\n",
            "    downstream_nodes: \"Trainer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.dsl.components.common.importer.Importer\"\n",
            "      }\n",
            "      id: \"schema_importer\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"result\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"artifact_uri\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"schema/penguin-tfdv-schema/schema.pbtxt\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"reimport\"\n",
            "        value {\n",
            "          field_value {\n",
            "            int_value: 0\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    downstream_nodes: \"ExampleValidator\"\n",
            "    downstream_nodes: \"Trainer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "      }\n",
            "      id: \"StatisticsGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"CsvExampleGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Examples\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"examples\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"statistics\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ExampleStatistics\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"exclude_splits\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"[]\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"CsvExampleGen\"\n",
            "    downstream_nodes: \"ExampleValidator\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.trainer.component.Trainer\"\n",
            "      }\n",
            "      id: \"Trainer\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"CsvExampleGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Examples\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"examples\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      inputs {\n",
            "        key: \"schema\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"schema_importer\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Schema\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"result\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"model\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Model\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      outputs {\n",
            "        key: \"model_run\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ModelRun\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"custom_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"null\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"eval_args\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"module_path\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"train_args\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"CsvExampleGen\"\n",
            "    upstream_nodes: \"schema_importer\"\n",
            "    downstream_nodes: \"Evaluator\"\n",
            "    downstream_nodes: \"Pusher\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "      }\n",
            "      id: \"Evaluator\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.Evaluator\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"baseline_model\"\n",
            "        value {\n",
            "          channels {\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Model\"\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      inputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"CsvExampleGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Examples\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"examples\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      inputs {\n",
            "        key: \"model\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"Trainer\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Model\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"model\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"blessing\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ModelBlessing\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      outputs {\n",
            "        key: \"evaluation\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ModelEvaluation\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"eval_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"SparseCategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -1e-10,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"species\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"sex\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"example_splits\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"null\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"CsvExampleGen\"\n",
            "    upstream_nodes: \"Trainer\"\n",
            "    downstream_nodes: \"Pusher\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
            "      }\n",
            "      id: \"ExampleValidator\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.ExampleValidator\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"schema\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"schema_importer\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Schema\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"result\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      inputs {\n",
            "        key: \"statistics\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"StatisticsGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"ExampleStatistics\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"statistics\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"anomalies\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ExampleAnomalies\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"exclude_splits\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"[]\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"StatisticsGen\"\n",
            "    upstream_nodes: \"schema_importer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.pusher.component.Pusher\"\n",
            "      }\n",
            "      id: \"Pusher\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-08-03T12:41:46.314475\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-tfdv-schema.Pusher\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"model\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"Trainer\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Model\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"model\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      inputs {\n",
            "        key: \"model_blessing\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"Evaluator\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-08-03T12:41:46.314475\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-tfdv-schema.Evaluator\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"ModelBlessing\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"blessing\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"pushed_model\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"PushedModel\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"custom_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"null\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"push_destination\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-tfdv\\\"\\n  }\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"Evaluator\"\n",
            "    upstream_nodes: \"Trainer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "runtime_spec {\n",
            "  pipeline_root {\n",
            "    field_value {\n",
            "      string_value: \"pipelines/penguin-tfdv-schema\"\n",
            "    }\n",
            "  }\n",
            "  pipeline_run_id {\n",
            "    field_value {\n",
            "      string_value: \"2021-08-03T12:41:46.314475\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "execution_mode: SYNC\n",
            "deployment_config {\n",
            "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
            "  value: \"\\n\\220\\001\\n\\007Trainer\\022\\204\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0221\\n/tfx.components.trainer.executor.GenericExecutor\\n\\234\\001\\n\\020ExampleValidator\\022\\207\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0224\\n2tfx.components.example_validator.executor.Executor\\n\\207\\001\\n\\tEvaluator\\022z\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022.\\n,\\n*tfx.components.evaluator.executor.Executor\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\n\\220\\001\\n\\rStatisticsGen\\022\\177\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\0223\\n1\\n/tfx.components.statistics_gen.executor.Executor\\n\\206\\001\\n\\006Pusher\\022|\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022)\\n\\'tfx.components.pusher.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver*b\\n0type.googleapis.com/ml_metadata.ConnectionConfig\\022.\\032,\\n(metadata/penguin-tfdv-schema/metadata.db\\020\\003\"\n",
            "}\n",
            "\n",
            "INFO:absl:Using deployment config:\n",
            " executor_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Evaluator\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.evaluator.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"ExampleValidator\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Pusher\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"StatisticsGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Trainer\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "custom_driver_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "metadata_connection_config {\n",
            "  sqlite {\n",
            "    filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
            "    connection_mode: READWRITE_OPENCREATE\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using connection config:\n",
            " sqlite {\n",
            "  filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
            "  connection_mode: READWRITE_OPENCREATE\n",
            "}\n",
            "\n",
            "INFO:absl:Component CsvExampleGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 39\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=39, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/39\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}), exec_properties={'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'input_base': '/tmp/tfx-datar21onp4k', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185'}, execution_output_uri='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/39/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/stateful_working_dir/2021-08-03T12:41:46.314475', tmp_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/39/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datar21onp4k\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T12:41:46.314475')\n",
            "INFO:absl:Generating examples.\n",
            "INFO:absl:Processing input csv data /tmp/tfx-datar21onp4k/* to TFExample.\n",
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "INFO:absl:Examples generated.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 39 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/39\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}) for execution 39\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component CsvExampleGen is finished.\n",
            "INFO:absl:Component schema_importer is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.dsl.components.common.importer.Importer\"\n",
            "  }\n",
            "  id: \"schema_importer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"result\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"artifact_uri\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"schema/penguin-tfdv-schema/schema.pbtxt\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"reimport\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Running as an importer node.\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Processing source uri: schema/penguin-tfdv-schema/schema.pbtxt, properties: {}, custom_properties: {}\n",
            "INFO:absl:Reusing existing artifact\n",
            "INFO:absl:Component schema_importer is finished.\n",
            "INFO:absl:Component StatisticsGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 41\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=41, input_dict={'examples': [Artifact(artifact: id: 33\n",
            "type_id: 6\n",
            "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994507883\n",
            "last_update_time_since_epoch: 1627994507883\n",
            ", artifact_type: id: 6\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/41\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:StatisticsGen:statistics:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/41/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/stateful_working_dir/2021-08-03T12:41:46.314475', tmp_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/41/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T12:41:46.314475')\n",
            "INFO:absl:Generating statistics for split train.\n",
            "INFO:absl:Statistics for split train written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/41/Split-train.\n",
            "INFO:absl:Generating statistics for split eval.\n",
            "INFO:absl:Statistics for split eval written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/41/Split-eval.\n",
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 41 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/41\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:StatisticsGen:statistics:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}) for execution 41\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component StatisticsGen is finished.\n",
            "INFO:absl:Component Trainer is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"schema_importer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"result\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"schema_importer\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 42\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=42, input_dict={'schema': [Artifact(artifact: id: 5\n",
            "type_id: 10\n",
            "uri: \"schema/penguin-tfdv-schema/schema.pbtxt\"\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627990857111\n",
            "last_update_time_since_epoch: 1627990857111\n",
            ", artifact_type: id: 10\n",
            "name: \"Schema\"\n",
            ")], 'examples': [Artifact(artifact: id: 33\n",
            "type_id: 6\n",
            "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994507883\n",
            "last_update_time_since_epoch: 1627994507883\n",
            ", artifact_type: id: 6\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model_run/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model_run:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")], 'model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Model\"\n",
            ")]}), exec_properties={'module_path': 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl', 'custom_config': 'null', 'train_args': '{}', 'eval_args': '{}'}, execution_output_uri='pipelines/penguin-tfdv-schema/Trainer/.system/executor_execution/42/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/Trainer/.system/stateful_working_dir/2021-08-03T12:41:46.314475', tmp_dir='pipelines/penguin-tfdv-schema/Trainer/.system/executor_execution/42/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"schema_importer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.schema_importer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"result\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"schema_importer\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T12:41:46.314475')\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "INFO:absl:udf_utils.get_fn {'module_path': 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl', 'custom_config': 'null', 'train_args': '{}', 'eval_args': '{}'} 'run_fn'\n",
            "INFO:absl:Installing 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpa0s89_tf', 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+3aa89e3eb08eebb43a41f8e85df3868ac3b273cc746a5cdcbc2eacd516acf9ce-py3-none-any.whl'.\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature bill_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature island has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sex has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature year has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature island has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sex has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature year has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature island has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sex has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature year has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature bill_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature island has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sex has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature year has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Using /tmp/tmp_v883gu3 as temporary training directory\n",
            "INFO:absl:Collect training examples.\n",
            "Features: {'bill_depth_mm': <tf.Tensor 'data:0' shape=(None, 1) dtype=float32>, 'bill_length_mm': <tf.Tensor 'data_1:0' shape=(None, 1) dtype=float32>, 'body_mass_g': <tf.Tensor 'data_2:0' shape=(None, 1) dtype=float32>, 'flipper_length_mm': <tf.Tensor 'data_3:0' shape=(None, 1) dtype=float32>, 'island': <tf.Tensor 'data_4:0' shape=(None, 1) dtype=string>, 'sex': <tf.Tensor 'data_5:0' shape=(None, 1) dtype=string>, 'year': <tf.Tensor 'data_6:0' shape=(None, 1) dtype=int64>}\n",
            "Label: Tensor(\"data_7:0\", shape=(None, 1), dtype=int64)\n",
            "INFO:absl:Squeezing labels to [batch_size] from [batch_size, 1].\n",
            "INFO:absl:Normalized features: {'bill_depth_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'bill_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'body_mass_g': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'flipper_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'island': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=string>), 'sex': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=string>), 'year': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>)}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4ed12bc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "      1/Unknown - 0s 339ms/step"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 1\n",
            "[INFO kernel.cc:393] Number of examples: 238\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 238\n",
            "Number of columns: 8\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 5 (62.5%)\n",
            "\tCATEGORICAL: 3 (37.5%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 5 (62.5%)\n",
            "\t0: \"bill_depth_mm\" NUMERICAL mean:17.0895 min:13.2 max:21.5 sd:1.90863\n",
            "\t1: \"bill_length_mm\" NUMERICAL mean:44.3345 min:32.1 max:59.6 sd:5.4891\n",
            "\t2: \"body_mass_g\" NUMERICAL mean:4230.78 min:2700 max:6300 sd:816.615\n",
            "\t3: \"flipper_length_mm\" NUMERICAL mean:201.466 min:172 max:231 sd:14.0735\n",
            "\t6: \"year\" NUMERICAL mean:2008.07 min:2007 max:2009 sd:0.814227\n",
            "\n",
            "CATEGORICAL: 3 (37.5%)\n",
            "\t4: \"island\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Biscoe\" 122 (51.2605%)\n",
            "\t5: \"sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 120 (50.4202%)\n",
            "\t7: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"bill_depth_mm\"\n",
            "features: \"bill_length_mm\"\n",
            "features: \"body_mass_g\"\n",
            "features: \"flipper_length_mm\"\n",
            "features: \"island\"\n",
            "features: \"sex\"\n",
            "features: \"year\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 238 example(s) and 7 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:2) done accuracy:0.946809 logloss:1.91722\n",
            "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:14) done accuracy:0.978814 logloss:0.358481\n",
            "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:12) done accuracy:0.97479 logloss:0.210673\n",
            "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:34) done accuracy:0.970588 logloss:0.214338\n",
            "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:33) done accuracy:0.978992 logloss:0.210231\n",
            "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:54) done accuracy:0.97479 logloss:0.212164\n",
            "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:53) done accuracy:0.983193 logloss:0.0781016\n",
            "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:73) done accuracy:0.983193 logloss:0.0781526\n",
            "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:84) done accuracy:0.983193 logloss:0.07843\n",
            "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:94) done accuracy:0.983193 logloss:0.0818193\n",
            "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:104) done accuracy:0.983193 logloss:0.0869738\n",
            "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:113) done accuracy:0.983193 logloss:0.0871306\n",
            "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:90) done accuracy:0.983193 logloss:0.0861096\n",
            "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:134) done accuracy:0.978992 logloss:0.0872409\n",
            "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:143) done accuracy:0.978992 logloss:0.0871166\n",
            "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:155) done accuracy:0.983193 logloss:0.0870852\n",
            "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:157) done accuracy:0.983193 logloss:0.0873469\n",
            "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:161) done accuracy:0.983193 logloss:0.0874645\n",
            "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:183) done accuracy:0.983193 logloss:0.0882212\n",
            "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:194) done accuracy:0.983193 logloss:0.0886113\n",
            "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:201) done accuracy:0.983193 logloss:0.0902008\n",
            "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:212) done accuracy:0.983193 logloss:0.0897336\n",
            "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:223) done accuracy:0.983193 logloss:0.0894794\n",
            "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:234) done accuracy:0.983193 logloss:0.0898833\n",
            "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:242) done accuracy:0.983193 logloss:0.0911265\n",
            "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:248) done accuracy:0.983193 logloss:0.0880949\n",
            "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:257) done accuracy:0.983193 logloss:0.0880439\n",
            "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:275) done accuracy:0.983193 logloss:0.0887904\n",
            "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.983193 logloss:0.0884162\n",
            "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:294) done accuracy:0.983193 logloss:0.088789\n",
            "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:274) done accuracy:0.983193 logloss:0.0871283\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.983193 logloss:0.0871283\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp_v883gu3\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 4566 node(s), and 7 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_test_function.<locals>.test_function_trained at 0x7f4ecf8d9e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 468ms/step - val_loss: 0.0000e+00 - val_accuracy: 0.9895\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f4ed34ce710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model: \"random_forest_model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (7):\n",
            "\tbill_depth_mm\n",
            "\tbill_length_mm\n",
            "\tbody_mass_g\n",
            "\tflipper_length_mm\n",
            "\tisland\n",
            "\tsex\n",
            "\tyear\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.           \"__LABEL\"  3.276547 ################\n",
            "    2.              \"year\"  3.261754 ###############\n",
            "    3.               \"sex\"  3.235646 ###############\n",
            "    4.       \"body_mass_g\"  2.701349 ###########\n",
            "    5.            \"island\"  2.102374 ######\n",
            "    6.     \"bill_depth_mm\"  2.053149 #####\n",
            "    7.    \"bill_length_mm\"  1.476428 #\n",
            "    8. \"flipper_length_mm\"  1.353696 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"flipper_length_mm\" 154.000000 ################\n",
            "    2.     \"bill_depth_mm\" 68.000000 ######\n",
            "    3.    \"bill_length_mm\" 58.000000 #####\n",
            "    4.       \"body_mass_g\" 11.000000 \n",
            "    5.            \"island\"  9.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.    \"bill_length_mm\" 677.000000 ################\n",
            "    2.     \"bill_depth_mm\" 446.000000 ##########\n",
            "    3.            \"island\" 339.000000 #######\n",
            "    4. \"flipper_length_mm\" 326.000000 #######\n",
            "    5.       \"body_mass_g\" 297.000000 ######\n",
            "    6.               \"sex\" 32.000000 \n",
            "    7.              \"year\" 16.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"bill_length_mm\" 22907.831867 ################\n",
            "    2. \"flipper_length_mm\" 22804.564500 ###############\n",
            "    3.     \"bill_depth_mm\" 11573.109912 ########\n",
            "    4.            \"island\" 11218.327308 #######\n",
            "    5.       \"body_mass_g\" 3447.309046 ##\n",
            "    6.               \"sex\" 287.164022 \n",
            "    7.              \"year\" 37.875296 \n",
            "\n",
            "\n",
            "\n",
            "Winner take all: true\n",
            "Out-of-bag evaluation: accuracy:0.983193 logloss:0.0871283\n",
            "Number of trees: 300\n",
            "Total number of nodes: 4566\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 15.22 StdDev: 3.11848\n",
            "Min: 9 Max: 25 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  9, 10) 10   3.33%   3.33% #\n",
            "[ 10, 11)  0   0.00%   3.33%\n",
            "[ 11, 12) 28   9.33%  12.67% ###\n",
            "[ 12, 13)  0   0.00%  12.67%\n",
            "[ 13, 14) 70  23.33%  36.00% #########\n",
            "[ 14, 15)  0   0.00%  36.00%\n",
            "[ 15, 16) 82  27.33%  63.33% ##########\n",
            "[ 16, 17)  0   0.00%  63.33%\n",
            "[ 17, 18) 68  22.67%  86.00% ########\n",
            "[ 18, 19)  0   0.00%  86.00%\n",
            "[ 19, 20) 21   7.00%  93.00% ###\n",
            "[ 20, 21)  0   0.00%  93.00%\n",
            "[ 21, 22)  9   3.00%  96.00% #\n",
            "[ 22, 23)  0   0.00%  96.00%\n",
            "[ 23, 24)  8   2.67%  98.67% #\n",
            "[ 24, 25)  0   0.00%  98.67%\n",
            "[ 25, 25]  4   1.33% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 2433 Average: 3.34238 StdDev: 1.01485\n",
            "Min: 1 Max: 7 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)  15   0.62%   0.62%\n",
            "[ 2, 3) 519  21.33%  21.95% ######\n",
            "[ 3, 4) 859  35.31%  57.25% ##########\n",
            "[ 4, 5) 761  31.28%  88.53% #########\n",
            "[ 5, 6) 226   9.29%  97.82% ###\n",
            "[ 6, 7)  43   1.77%  99.59% #\n",
            "[ 7, 7]  10   0.41% 100.00%\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 2433 Average: 29.3465 StdDev: 30.3453\n",
            "Min: 5 Max: 107 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  10) 1240  50.97%  50.97% ##########\n",
            "[  10,  15)  128   5.26%  56.23% #\n",
            "[  15,  20)   56   2.30%  58.53%\n",
            "[  20,  25)   43   1.77%  60.30%\n",
            "[  25,  30)   75   3.08%  63.38% #\n",
            "[  30,  35)   75   3.08%  66.46% #\n",
            "[  35,  41)   87   3.58%  70.04% #\n",
            "[  41,  46)   73   3.00%  73.04% #\n",
            "[  46,  51)   51   2.10%  75.13%\n",
            "[  51,  56)   45   1.85%  76.98%\n",
            "[  56,  61)   30   1.23%  78.22%\n",
            "[  61,  66)   38   1.56%  79.78%\n",
            "[  66,  71)   60   2.47%  82.24%\n",
            "[  71,  77)   72   2.96%  85.20% #\n",
            "[  77,  82)  106   4.36%  89.56% #\n",
            "[  82,  87)   99   4.07%  93.63% #\n",
            "[  87,  92)   89   3.66%  97.29% #\n",
            "[  92,  97)   43   1.77%  99.05%\n",
            "[  97, 102)   17   0.70%  99.75%\n",
            "[ 102, 107]    6   0.25% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t677 : bill_length_mm [NUMERICAL]\n",
            "\t446 : bill_depth_mm [NUMERICAL]\n",
            "\t339 : island [CATEGORICAL]\n",
            "\t326 : flipper_length_mm [NUMERICAL]\n",
            "\t297 : body_mass_g [NUMERICAL]\n",
            "\t32 : sex [CATEGORICAL]\n",
            "\t16 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t154 : flipper_length_mm [NUMERICAL]\n",
            "\t68 : bill_depth_mm [NUMERICAL]\n",
            "\t58 : bill_length_mm [NUMERICAL]\n",
            "\t11 : body_mass_g [NUMERICAL]\n",
            "\t9 : island [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t243 : bill_length_mm [NUMERICAL]\n",
            "\t211 : flipper_length_mm [NUMERICAL]\n",
            "\t185 : island [CATEGORICAL]\n",
            "\t164 : bill_depth_mm [NUMERICAL]\n",
            "\t82 : body_mass_g [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t450 : bill_length_mm [NUMERICAL]\n",
            "\t308 : bill_depth_mm [NUMERICAL]\n",
            "\t304 : island [CATEGORICAL]\n",
            "\t279 : flipper_length_mm [NUMERICAL]\n",
            "\t183 : body_mass_g [NUMERICAL]\n",
            "\t9 : sex [CATEGORICAL]\n",
            "\t3 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t618 : bill_length_mm [NUMERICAL]\n",
            "\t422 : bill_depth_mm [NUMERICAL]\n",
            "\t333 : island [CATEGORICAL]\n",
            "\t314 : flipper_length_mm [NUMERICAL]\n",
            "\t259 : body_mass_g [NUMERICAL]\n",
            "\t24 : sex [CATEGORICAL]\n",
            "\t9 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t675 : bill_length_mm [NUMERICAL]\n",
            "\t444 : bill_depth_mm [NUMERICAL]\n",
            "\t339 : island [CATEGORICAL]\n",
            "\t326 : flipper_length_mm [NUMERICAL]\n",
            "\t296 : body_mass_g [NUMERICAL]\n",
            "\t32 : sex [CATEGORICAL]\n",
            "\t16 : year [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t1762 : HigherCondition\n",
            "\t371 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t291 : HigherCondition\n",
            "\t9 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t700 : HigherCondition\n",
            "\t185 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1223 : HigherCondition\n",
            "\t313 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t1622 : HigherCondition\n",
            "\t357 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t1757 : HigherCondition\n",
            "\t371 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.946809 logloss:1.91722\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.978814 logloss:0.358481\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.97479 logloss:0.210673\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.970588 logloss:0.214338\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.978992 logloss:0.210231\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.97479 logloss:0.212164\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0781016\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0781526\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.983193 logloss:0.07843\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0818193\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0869738\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0871306\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0861096\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.978992 logloss:0.0872409\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.978992 logloss:0.0871166\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0870852\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0873469\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0874645\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0882212\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0886113\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0902008\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0897336\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0894794\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0898833\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0911265\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0880949\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0880439\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0887904\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0884162\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.983193 logloss:0.088789\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.983193 logloss:0.0871283\n",
            "\n",
            "None\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7f4ecf7763b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "INFO:tensorflow:Assets written to: pipelines/penguin-tfdv-schema/Trainer/model/42/Format-Serving/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Training complete. Model written to pipelines/penguin-tfdv-schema/Trainer/model/42/Format-Serving. ModelRun written to pipelines/penguin-tfdv-schema/Trainer/model_run/42\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 42 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model_run/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model_run:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")], 'model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Model\"\n",
            ")]}) for execution 42\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer is finished.\n",
            "INFO:absl:Component Evaluator is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"SparseCategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -1e-10,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"species\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"sex\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 43\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=43, input_dict={'baseline_model': [Artifact(artifact: id: 19\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/22\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:49:06.441731:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627991356621\n",
            "last_update_time_since_epoch: 1627991356621\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            "), Artifact(artifact: id: 32\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/37\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:00.364375:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994470794\n",
            "last_update_time_since_epoch: 1627994470794\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            "), Artifact(artifact: id: 36\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994516837\n",
            "last_update_time_since_epoch: 1627994516837\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            "), Artifact(artifact: id: 24\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/27\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:35:32.277099:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994142811\n",
            "last_update_time_since_epoch: 1627994142811\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            "), Artifact(artifact: id: 7\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/7\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T11:40:55.550632:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627990913520\n",
            "last_update_time_since_epoch: 1627990913520\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            "), Artifact(artifact: id: 28\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/32\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:38:17.423965:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994308412\n",
            "last_update_time_since_epoch: 1627994308412\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            ")], 'model': [Artifact(artifact: id: 36\n",
            "type_id: 13\n",
            "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/42\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994516837\n",
            "last_update_time_since_epoch: 1627994516837\n",
            ", artifact_type: id: 13\n",
            "name: \"Model\"\n",
            ")], 'examples': [Artifact(artifact: id: 33\n",
            "type_id: 6\n",
            "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:14417,xor_checksum:1627990185,sum_checksum:1627990185\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.0.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1627994507883\n",
            "last_update_time_since_epoch: 1627994507883\n",
            ", artifact_type: id: 6\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Evaluator/evaluation/43\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Evaluator:evaluation:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelEvaluation\"\n",
            ")], 'blessing': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Evaluator/blessing/43\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-tfdv-schema:2021-08-03T12:41:46.314475:Evaluator:blessing:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelBlessing\"\n",
            ")]}), exec_properties={'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": -1e-10,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"species\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"sex\"\\n      ]\\n    }\\n  ]\\n}'}, execution_output_uri='pipelines/penguin-tfdv-schema/Evaluator/.system/executor_execution/43/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/Evaluator/.system/stateful_working_dir/2021-08-03T12:41:46.314475', tmp_dir='pipelines/penguin-tfdv-schema/Evaluator/.system/executor_execution/43/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-08-03T12:41:46.314475\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-tfdv-schema.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-08-03T12:41:46.314475\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-tfdv-schema.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"SparseCategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -1e-10,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"species\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"sex\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
            ", pipeline_run_id='2021-08-03T12:41:46.314475')\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "ERROR:absl:Execution 43 failed.\n",
            "INFO:absl:Cleaning up stateless execution info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-67a94d714a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mschema_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAVED_SCHEMA_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrainer_module_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAINER_MODULE_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mserving_model_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSERVING_MODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     ),\n\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/orchestration/local/local_dag_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m     89\u001b[0m             custom_driver_spec=custom_driver_spec)\n\u001b[1;32m     90\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Component %s is running.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mcomponent_launcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Component %s is finished.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/orchestration/portable/launcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m               executor_watcher.address)\n\u001b[1;32m    485\u001b[0m           \u001b[0mexecutor_watcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mexecutor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         execution_output = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/orchestration/portable/launcher.py\u001b[0m in \u001b[0;36m_run_executor\u001b[0;34m(self, execution_info)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0moutputs_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_output_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0mexecutor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_operator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/orchestration/portable/beam_executor_operator.py\u001b[0m in \u001b[0;36mrun_executor\u001b[0;34m(self, execution_info)\u001b[0m\n\u001b[1;32m     87\u001b[0m         pipeline_run_id=execution_info.pipeline_run_id)\n\u001b[1;32m     88\u001b[0m     \u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpython_executor_operator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/orchestration/portable/python_executor_operator.py\u001b[0m in \u001b[0;36mrun_with_executor\u001b[0;34m(execution_info, executor)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   result = executor.Do(execution_info.input_dict, output_dict,\n\u001b[0;32m---> 55\u001b[0;31m                        execution_info.exec_properties)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# If result is not returned from the Do function, then try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/components/evaluator/executor.py\u001b[0m in \u001b[0;36mDo\u001b[0;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m    112\u001b[0m         input_dict[BASELINE_MODEL_KEY]) > 1:\n\u001b[1;32m    113\u001b[0m       \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m       \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASELINE_MODEL_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m       raise ValueError('There can be only one baseline model, there are %s.' %\n\u001b[1;32m    116\u001b[0m                        (len(input_dict[BASELINE_MODEL_KEY])))\n",
            "\u001b[0;31mValueError\u001b[0m: There can be only one baseline model, there are 6."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiasiGgBy-2q"
      },
      "source": [
        "context = InteractiveContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB3lffHIzKly"
      },
      "source": [
        "example_gen = tfx.components.CsvExampleGen(input_base=DATA_ROOT)\n",
        "context.run(example_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Demu5JjszdQ2"
      },
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(2):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApyLWpXKQ87m"
      },
      "source": [
        "tfrecord_filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94PLih7u3Q4"
      },
      "source": [
        "## 2. Schema Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgtxUgWl6vxo"
      },
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)\n",
        "\n",
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40xwbTQZu_Rh"
      },
      "source": [
        "def _create_schema_pipeline(pipeline_name: str, \n",
        "                            pipeline_root: str, \n",
        "                            data_root: str,\n",
        "                            metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "  # NEW: Computes statistics over data for visualization and schema generation.\n",
        "  statistics_gen = tfx.components.StatisticsGen(\n",
        "      examples=example_gen.outputs['examples'])\n",
        "\n",
        "  # NEW: Generates schema based on the generated statistics.\n",
        "  schema_gen = tfx.components.SchemaGen(\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "  \n",
        "\n",
        "  # Following three components will be included in the pipeline.\n",
        "  components = [\n",
        "      example_gen,\n",
        "      statistics_gen,\n",
        "      schema_gen,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPApi1rivMrG"
      },
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_schema_pipeline(\n",
        "      pipeline_name=SCHEMA_PIPELINE_NAME,\n",
        "      pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      metadata_path=SCHEMA_METADATA_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9RcPD2fu7Ae"
      },
      "source": [
        "### 2.1 Check output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDULG2DxviDp"
      },
      "source": [
        "from ml_metadata.proto import metadata_store_pb2\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.portable.mlmd import execution_lib\n",
        "\n",
        "# TODO(b/171447278): Move these functions into the TFX library.\n",
        "\n",
        "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
        "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
        "  context = metadata.store.get_context_by_type_and_name(\n",
        "      'node', f'{pipeline_name}.{component_id}')\n",
        "  executions = metadata.store.get_executions_by_context(context.id)\n",
        "  latest_execution = max(executions,\n",
        "                         key=lambda e:e.last_update_time_since_epoch)\n",
        "  return execution_lib.get_artifacts_dict(metadata, latest_execution.id, \n",
        "                                          metadata_store_pb2.Event.OUTPUT)\n",
        "\n",
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.experimental.interactive import visualizations\n",
        "\n",
        "def visualize_artifacts(artifacts):\n",
        "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
        "  for artifact in artifacts:\n",
        "    visualization = visualizations.get_registry().get_visualization(\n",
        "        artifact.type_name)\n",
        "    if visualization:\n",
        "      visualization.display(artifact)\n",
        "\n",
        "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
        "standard_visualizations.register_standard_visualizations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feSrlPBzu26g"
      },
      "source": [
        "# Non-public APIs, just for showcase.\n",
        "from tfx.orchestration.metadata import Metadata\n",
        "from tfx.types import standard_component_specs\n",
        "\n",
        "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
        "    SCHEMA_METADATA_PATH)\n",
        "\n",
        "with Metadata(metadata_connection_config) as metadata_handler:\n",
        "  # Find output artifacts from MLMD.\n",
        "  stat_gen_output = get_latest_artifacts(metadata_handler, SCHEMA_PIPELINE_NAME,\n",
        "                                         'StatisticsGen')\n",
        "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
        "\n",
        "  schema_gen_output = get_latest_artifacts(metadata_handler,\n",
        "                                           SCHEMA_PIPELINE_NAME, 'SchemaGen')\n",
        "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP36Lrugvyto"
      },
      "source": [
        "visualize_artifacts(stats_artifacts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWLOZDAev5fk"
      },
      "source": [
        "visualize_artifacts(schema_artifacts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaqW3jft3iv7"
      },
      "source": [
        "import shutil\n",
        "\n",
        "_schema_filename = 'schema.pbtxt'\n",
        "SCHEMA_PATH = 'schema'\n",
        "\n",
        "os.makedirs(SCHEMA_PATH, exist_ok=True)\n",
        "_generated_path = os.path.join(schema_artifacts[0].uri, _schema_filename)\n",
        "\n",
        "# Copy the 'schema.pbtxt' file from the artifact uri to a predefined path.\n",
        "shutil.copy(_generated_path, SCHEMA_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsu-w4J_3sUa"
      },
      "source": [
        "## 3. Validate schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5vJVgqu6j_3"
      },
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsKy84P07Ksj"
      },
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhpTqMSS7TYL"
      },
      "source": [
        "## 4. Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QO_r1PuWyJz"
      },
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9zeAfYNewU0"
      },
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "# from tfx_bsl.public import tfxio\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "from wurlitzer import sys_pipes\n",
        "\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 238\n",
        "_EVAL_BATCH_SIZE = 95\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "    \n",
        "  dataset = data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=None, num_epochs=1),\n",
        "      schema)\n",
        "  \n",
        "  def prepare_label(feature_dict):\n",
        "    print(type(feature_dict))\n",
        "    print(feature_dict)\n",
        "    label_dict = tf.sparse.to_dense(\n",
        "        feature_dict.pop(_LABEL_KEY), default_value=None, validate_indices=True, name=None\n",
        "    )\n",
        "    return feature_dict, label_dict\n",
        "\n",
        "  dataset = dataset.map(prepare_label)\n",
        "  return dataset\n",
        "\n",
        "def _build_tfdf_model():\n",
        "    model = tfdf.keras.RandomForestModel()\n",
        "    model.compile(metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  schema = tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema_pb2.Schema())\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "#   for features, label in train_dataset.take(1):  # only take first element of dataset\n",
        "#     print('*************')\n",
        "#     print(features)\n",
        "#     print(label)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  model = _build_tfdf_model()\n",
        "  with sys_pipes():\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        # steps_per_epoch=fn_args.train_steps,\n",
        "        validation_data=eval_dataset)\n",
        "        # validation_steps=fn_args.eval_steps)\n",
        "    print(model.summary())\n",
        "\n",
        "  model.make_inspector().export_to_tensorboard(fn_args.model_run_dir)\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjJ_tkC7Y7l"
      },
      "source": [
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(_trainer_module_file),\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=tfx.proto.TrainArgs(),\n",
        "    eval_args=tfx.proto.EvalArgs())\n",
        "context.run(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kf3xUAqV6Ee"
      },
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "pp.pprint(os.listdir(model_artifact_dir))\n",
        "model_dir = os.path.join(model_artifact_dir, 'Format-Serving')\n",
        "pp.pprint(os.listdir(model_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFN_4HjZV8W3"
      },
      "source": [
        "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "print(model_run_artifact_dir)\n",
        "os.listdir(model_run_artifact_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP_w5CR6ABoh"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_artifact_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQaHakEAC6TJ"
      },
      "source": [
        "## 5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWV36Vn2C5xS"
      },
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # This assumes a serving model with signature 'serving_default'. If\n",
        "        # using estimator based EvalSavedModel, add signature_name: 'eval' and \n",
        "        # remove the label_key.\n",
        "        tfma.ModelSpec(label_key='species')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='SparseCategoricalAccuracy',\n",
        "                  threshold=tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.5}),\n",
        "                    # Change threshold will be ignored if there is no\n",
        "                    # baseline model resolved from MLMD (first run).\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                        absolute={'value': -1e-10})))\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['sex'])\n",
        "    ])\n",
        "\n",
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(\n",
        "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
        "              'latest_blessed_model_resolver')\n",
        "context.run(model_resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ip2-p8SkoSZ"
      },
      "source": [
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwY3VuyjkrvL"
      },
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hh9QKaYkz4O"
      },
      "source": [
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='sex')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJkJ31Rxk-d0"
      },
      "source": [
        "blessing_uri = evaluator.outputs.blessing.get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPqZshI0xQeu"
      },
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfaewA7Lzmv4"
      },
      "source": [
        "## 6. Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPmRWUvsxbaV"
      },
      "source": [
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=tfx.proto.PushDestination(\n",
        "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "            base_directory=SERVING_MODEL_DIR)))\n",
        "context.run(pusher)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH1p6wgJztgu"
      },
      "source": [
        "push_uri = pusher.outputs.pushed_model.get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IsvGSQa0hJX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}